{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4765c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee986dfa",
   "metadata": {},
   "source": [
    "## Hyperbole Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c456a",
   "metadata": {},
   "source": [
    "This notebook contains a random forest model that has been trained on the feature engineered dataset (which was created in <b>hyperbole_feature_engineering.ipynb</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cdfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_PREPARED_DATASET = \"../../data/hyperbole_detection/hyperboles_feature_engineered.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperboles = pd.read_csv(PATH_TO_PREPARED_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperboles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27579ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df_hyperboles)) < 0.8\n",
    "\n",
    "df_train = df_hyperboles[msk]\n",
    "\n",
    "df_test = df_hyperboles[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1442d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_tf_idf_features = vectorizer.fit_transform(df_train['german']).toarray()\n",
    "test_tf_idf_features  = vectorizer.transform(df_test['german']).toarray()\n",
    "\n",
    "# Converting above list to DataFrame\n",
    "train_tf_idf = pd.DataFrame(train_tf_idf_features)\n",
    "test_tf_idf = pd.DataFrame(test_tf_idf_features)\n",
    "\n",
    "# Separating train and test labels from all features\n",
    "train_Y = df_train['label']\n",
    "test_Y = df_test['label']\n",
    "\n",
    "# Listing all features\n",
    "features = ['imageability', 'polarity_senti_ws',\n",
    "       'polarity_text_blob', 'subjectivity_huggingface', 'vader_positive',\n",
    "       'vader_neutral', 'vader_negative', 'vader_compound']\n",
    "\n",
    "# Merging the features with above TF-IDF. \n",
    "train_tf_idf = train_tf_idf.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "\n",
    "test_tf_idf = test_tf_idf.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "\n",
    "train = pd.merge(train_tf_idf,df_train[features],left_index=True, right_index=True)\n",
    "train = train.drop(columns=['index'])\n",
    "\n",
    "test  = pd.merge(test_tf_idf,df_test[features],left_index=True, right_index=True)\n",
    "test = test.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, train_Y, test_size=0.2, random_state = 42)# Random Forest Classifier\n",
    "_RandomForestClassifier = RandomForestClassifier(n_estimators = 1000, min_samples_split = 15, random_state = 42)\n",
    "_RandomForestClassifier.fit(X_train, y_train)\n",
    "_RandomForestClassifier_prediction = _RandomForestClassifier.predict(X_test)\n",
    "val_RandomForestClassifier_prediction = _RandomForestClassifier.predict(test)\n",
    "\n",
    "print(\"Accuracy => \", round(accuracy_score(_RandomForestClassifier_prediction, y_test)*100, 2))\n",
    "print(\"\\nRandom Forest Classifier results: \\n\")\n",
    "print(classification_report(y_test, _RandomForestClassifier_prediction, target_names = ['real', 'fake']))\n",
    "print(\"Validation Accuracy => \", round(accuracy_score(val_RandomForestClassifier_prediction, test_Y)*100, 2))\n",
    "print(\"\\nValidation Random Forest Classifier results: \\n\")\n",
    "print(classification_report(test_Y, val_RandomForestClassifier_prediction, target_names = ['real', 'fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367ca28",
   "metadata": {},
   "source": [
    "## Following the approach by Troiano et al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd77bf",
   "metadata": {},
   "source": [
    "In this following section the same types of models as in Troiano et al. are going to be trained. Unfortunately we do not know which model parameters were set, therefore the default configuration is going to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f666b",
   "metadata": {},
   "source": [
    "### Defining the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02c921",
   "metadata": {},
   "source": [
    "Helper class that is used to create the table at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \n",
    "    def __init__(self, name, clf):\n",
    "        \n",
    "        self.name = name\n",
    "        self.clf = clf\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def set_name(self,name):\n",
    "        self.name = name\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return self.clf\n",
    "\n",
    "    def set_clf(self, clf):\n",
    "        self.clf = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02187e14",
   "metadata": {},
   "source": [
    "All of the following classifiers besides random forest were used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr_Classifier = Classifier(\"LR\",LogisticRegression())\n",
    "Knn_Classifier = Classifier(\"KNN\",KNeighborsClassifier())\n",
    "Nb_Classifier = Classifier(\"NB\",GaussianNB())\n",
    "Dt_Classifier = Classifier(\"DT\", DecisionTreeClassifier())\n",
    "Svm_Classifier = Classifier(\"SVM\", make_pipeline(StandardScaler(), SVC(gamma='auto')))\n",
    "Lda_Classifier = Classifier(\"LDA\", LinearDiscriminantAnalysis())\n",
    "Rf_Classifier = Classifier(\"RF\", RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb301b95",
   "metadata": {},
   "source": [
    "A list containing all the classifiers which were defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_classifiers = [\n",
    "    Lr_Classifier, Knn_Classifier, Nb_Classifier, \n",
    "    Dt_Classifier, Svm_Classifier, Lda_Classifier, Rf_Classifier\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47bd97",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_GOOGLE_TRANSLATED_ALL = \"../../data/hyperbole_detection/hyperboles_feature_engineered.csv\"\n",
    "\n",
    "DATASET_GOOGLE_TRANSLATED_400 = \"../../data/hyperbole_detection/hyperboles_google_translated_feature_engineered.csv\"\n",
    "\n",
    "DATASET_MANUALLY_TRANSLATED_400 = \"../../data/hyperbole_detection/hyperboles_manually_translated_feature_engineered.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6de29c",
   "metadata": {},
   "source": [
    "The following block is used to load the different dataframes.\n",
    "\n",
    "**df_input_machine_translated_all** contains all the sentences in machine translated form, created by google translate\n",
    "\n",
    "**df_input_machine_translated_400** contains 400 sentences which were machine translated by google translate. This dataset was created so that a comparison between manually translated sentences and the machine translated sentences is possible\n",
    "\n",
    "**df_input_manually_translated_400** contains the 400 manually translated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_machine_translated_all = pd.read_csv(DATASET_GOOGLE_TRANSLATED_ALL)\n",
    "df_input_machine_translated_400 = pd.read_csv(DATASET_GOOGLE_TRANSLATED_400)\n",
    "df_input_manually_translated_400 = pd.read_csv(DATASET_MANUALLY_TRANSLATED_400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714535c3",
   "metadata": {},
   "source": [
    "### Training, Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af38fbd",
   "metadata": {},
   "source": [
    "The following block contains the relevant columns for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395af9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = ['imageability', 'polarity_senti_ws',\n",
    "       'polarity_text_blob', 'subjectivity_huggingface', 'vader_positive',\n",
    "       'vader_neutral', 'vader_negative', 'vader_compound']\n",
    "\n",
    "y_column = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f4440",
   "metadata": {},
   "source": [
    "The functions defined below are used to train the models and to evaluate them. The results can then be presented in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a68d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resulting_table(experiment_names, experiment_dfs, list_X_columns, list_y_column, classifiers):\n",
    "    results = []\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    while index < len(experiment_dfs):\n",
    "        resulting_series = create_result_column(experiment_dfs[index], \n",
    "            list_X_columns[index], list_y_column[index], classifiers)\n",
    "        \n",
    "        results.append(resulting_series)\n",
    "        index += 1\n",
    "        \n",
    "    resulting_df = pd.concat(results, axis=1)\n",
    "    resulting_df.columns = experiment_names\n",
    "    \n",
    "    return resulting_df\n",
    "    \n",
    "\n",
    "def create_result_column(df, X_columns, y_column, classifiers, cv_k = 10):\n",
    "    test_accuracies = []\n",
    "    clf_names = get_names_from_classifiers(classifiers)\n",
    "    \n",
    "    X, y = get_X_and_y(df, X_columns, y_column)\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        \n",
    "        accuracy = get_mean_accuracy_from_cv(classifier.get_clf(), X, y, cv_k)\n",
    "        \n",
    "        test_accuracies.append(accuracy)\n",
    "    \n",
    "    return pd.Series(test_accuracies, index=clf_names)\n",
    "\n",
    "def get_names_from_classifiers(classifiers):\n",
    "    names = []\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        names.append(clf.get_name())\n",
    "        \n",
    "    return names\n",
    "\n",
    "def get_X_and_y(df, X_columns, y_column):\n",
    "    X = df.loc[:,X_columns]\n",
    "    y = df[y_column]\n",
    "    \n",
    "    return (X, y)\n",
    "\n",
    "def get_mean_accuracy_from_cv(clf, X, y, cv_k):\n",
    "    cv_results = cross_validate(clf, X, y, cv=cv_k,scoring=('r2', 'accuracy'))\n",
    "    \n",
    "    return cv_results[\"test_accuracy\"].mean()\n",
    "\n",
    "def train_model(classifier, X_train, y_train):\n",
    "    return classifier.fit(X_train, y_train)\n",
    "\n",
    "def get_accuracy(model, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    return (train_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ffa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_names = [\"machine_translated_all\", \"machine_translated_400\", \"manually_translated_400\"]\n",
    "list_dfs = [df_input_machine_translated_all, df_input_machine_translated_400,df_input_manually_translated_400]\n",
    "X_columns_list = [X_columns, X_columns, X_columns]\n",
    "y_column_list = [y_column, y_column, y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = create_resulting_table(experiment_names, list_dfs, X_columns_list, y_column_list, list_of_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfcd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
