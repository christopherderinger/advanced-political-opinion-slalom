{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a237f",
   "metadata": {},
   "source": [
    "Format all the rows in the textfile so that the urls are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f14218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wiktionary_urls.txt\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns = [\"unclean_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30735c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(row):\n",
    "    if not row.startswith(\"http\"):\n",
    "        return row.split(\" \")[1]\n",
    "    else:\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"clean_url\"] = df[\"unclean_url\"].apply(lambda row: format_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(2400,2700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca86fd",
   "metadata": {},
   "source": [
    "Download the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c78590",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TARGET_FOLDER = \"downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url,target_path, filename):\n",
    "    urllib.request.urlretrieve(url, target_path + filename)\n",
    "    sleep(0.1)\n",
    "    \n",
    "def downloader(df, starting_index, max_index, target_path):\n",
    "    \n",
    "    current_starter = starting_index\n",
    "    current_end = current_starter + 300\n",
    "    \n",
    "    while current_end <= max_index:\n",
    "    \n",
    "        index = list(range(current_starter,current_end))\n",
    "    \n",
    "        df.iloc[index].apply(\n",
    "        lambda row: download(row[\"clean_url\"],target_path,\n",
    "                         \"document_{num}.html\".format(num=row.name))\n",
    "        ,axis=1)\n",
    "        \n",
    "        sleep(5)\n",
    "        print(\"Done with download from {start} to {end}\".format(start=current_starter, end=current_end))\n",
    "        \n",
    "        current_starter = current_starter + 300\n",
    "        current_end = current_starter + 300\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee92f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader(df, 13800, 14100,PATH_TO_TARGET_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e798a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(14100,14109))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381059d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3873b08",
   "metadata": {},
   "source": [
    "Extract information from the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information(filename):\n",
    "    with open(filename) as fp:\n",
    "        soup = BeautifulSoup(fp, 'html.parser')\n",
    "        \n",
    "    tables = soup.find_all(\"table\", class_=\"inflection-table\")\n",
    "    table = \"\"\n",
    "    \n",
    "    if len(tables) > 0:\n",
    "        table = tables[0]\n",
    "    else:\n",
    "        print(\"Does not have any table\")\n",
    "        print(filename)\n",
    "        return (\"-\",\"-\",\"-\")\n",
    "    \n",
    "    tds = table.find_all(\"td\")\n",
    "    \n",
    "    texts = []\n",
    "\n",
    "    for td in tds:\n",
    "        splitted = td.text.split(\"\\n\")\n",
    "        \n",
    "        if len(splitted) > 2:\n",
    "            texts.append(splitted[0] + \"_\" + splitted[2])\n",
    "        else:\n",
    "            texts.append(splitted[0])\n",
    "    \n",
    "    return tuple(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_information(\"test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee3c74",
   "metadata": {},
   "source": [
    "Do it for all html documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab18510",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"downloads/\"\n",
    "TARGET_FOLDER = \"downloads/done/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files\n",
    "files = Path(INPUT_FOLDER).glob('*.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7503b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb318bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    information = get_information(f)\n",
    "    data.append(information)\n",
    "    current_filename = f.stem\n",
    "    os.rename(f, TARGET_FOLDER + current_filename + \".html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ac128",
   "metadata": {},
   "source": [
    "Turn into resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a753709",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in to_repair_files:\n",
    "    current_filename = f.stem.split(\"done\")[1]\n",
    "    os.rename(f, INPUT_FOLDER + current_filename + \".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944bc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faulty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d490fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "while index < len(data):\n",
    "    if len(data[index]) > 3:\n",
    "        faulty_data.append(data[index])\n",
    "        data.pop(index)\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp in data:\n",
    "    if len(dp) > 3:\n",
    "        print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['positiv', 'komparativ', 'superlativ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"nearly_all.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_have_same_stem(row):\n",
    "    pos = row[\"positiv\"]\n",
    "    komp = row[\"komparativ\"]\n",
    "    sup = row[\"superlativ\"]\n",
    "    \n",
    "    if pos in komp and pos in sup:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"have_same_stem\"] = df.apply(lambda row: words_have_same_stem(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e28952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object where isna() is true need to be dropped\n",
    "df_irregular = df[~df[\"have_same_stem\"] & (df[\"komparativ\"] != \"—\") & (df[\"superlativ\"] != \"—\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_irregular.to_csv(\"adjektive_irreguläre_steigerung.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ada7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set(df_irregular[\"komparativ\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"besser\" in set(df[\"komparativ\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
