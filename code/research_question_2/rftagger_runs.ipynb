{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d39b75",
   "metadata": {},
   "source": [
    "This notebook aims at showing how the part-of-speech tags were added using the RFTagger. The RFTagger is not installed in the docker container, therefore the code cannot be executed. It had to be restarted manually multiple times during the execution, in total it took around 27 hours until it was finished. Batches were used so that it was possible to see which statements have already been processed, they have always been changed manually, so that I was able to control before whether the previous batch was successful or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output, run\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pandarallel import pandarallel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d7e73",
   "metadata": {},
   "source": [
    "Run the make command so that the RFTagger is built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89638d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run([\"make\"], cwd=\"RFTagger/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batches(df,starting_index, max_len):\n",
    "    \n",
    "    if starting_index > max_len:\n",
    "        print(\"max_len must not be less than starting_index\")\n",
    "        return\n",
    "    \n",
    "    if max_len < 2000:\n",
    "        print(\"Please specify a number larger than 2000\")\n",
    "        return\n",
    "    \n",
    "    # the run should be done in 1000 piece batches\n",
    "    chosen_index = list(range(starting_index,starting_index+1000))\n",
    "    \n",
    "    # the 1000 piece batches are stored in separate .csv files with the naming convention\n",
    "    # batch_<starting_index>_<ending_index>.csv (batch_0_999.csv)\n",
    "    file_name = get_filename(chosen_index)\n",
    "    \n",
    "    while chosen_index[-1] <= (max_len):\n",
    "        df_current = df.iloc[chosen_index]\n",
    "        df_current[\"tagged\"] = df_current.parallel_apply(\n",
    "            lambda row: tag(\"test_{}\".format(row.name),row[1]),axis=1)\n",
    "        \n",
    "        df_current.to_csv(file_name,index=False)\n",
    "        new_index = [x+1000 for x in chosen_index]\n",
    "        \n",
    "        chosen_index = new_index\n",
    "        file_name = get_filename(chosen_index)\n",
    "    \n",
    "\n",
    "def get_filename(index):\n",
    "    return \"batch_{start}_{end}.csv\".format(start=index[0],end=index[-1])\n",
    "\n",
    "def tag(filename, text):\n",
    "    file = open(\"RFTagger/{}\".format(filename),\"w\")\n",
    "    file.write(\"\\n\\n\".join(\"\\n\".join(word_tokenize(sentence, language='german')) for sentence in sent_tokenize(text, language='german')))\n",
    "    file.close()\n",
    "    \n",
    "    res = check_output([\"src/rft-annotate\", \"lib/german.par\", filename], cwd=\"RFTagger\").decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "    os.system(\"rm RFTagger/{}\".format(filename))\n",
    "    \n",
    "    return ' '.join(res)\n",
    "\n",
    "def contains(text,tag):\n",
    "    regexp = re.compile(r'{}'.format(tag))\n",
    "    return bool(regexp.search(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d7584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/protocols/all_parsed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c4157",
   "metadata": {},
   "source": [
    "This is just an example, all the batches were created like this, it took around 27 hours in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e532ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_batches(df, 60000, 63000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980ab51",
   "metadata": {},
   "source": [
    "The last 909 entries were completed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb44c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.tail(909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short[\"tagged\"] = df_short.parallel_apply(lambda row: tag(\"test_{}\".format(row.name),row[1]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8193cfd9",
   "metadata": {},
   "source": [
    "The batches were stored like seen here with start and end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f58a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short.to_csv(\"batch_63000_63909.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db86244",
   "metadata": {},
   "source": [
    "The batches were concatenated like seen in the following, this code cannot be executed as the path does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = Path(PATH_TO_FOLDER_WITH_BATCHES).glob(\"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c75735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_batches = list()\n",
    "\n",
    "for f in files:\n",
    "    data = pd.read_csv(f)\n",
    "    dfs_batches.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"all_tagged.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
