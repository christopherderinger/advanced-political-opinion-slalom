{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fe4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"GerVADER/\")\n",
    "import GerVADER.vaderSentimentGER as gv\n",
    "\n",
    "from typing import Callable, List, Dict, TextIO, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d1d7f",
   "metadata": {},
   "source": [
    "# Hyperbole Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25c501",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c3d90",
   "metadata": {},
   "source": [
    "The approach which is followed in this notebook is taken from the paper \"A Computational Exploration of Exaggeration\" [1] \n",
    "\n",
    "[1] Troiano, Enrica, et al. \"A computational exploration of \n",
    "exaggeration.\" Proceedings of the 2018 Conference on Empirical \n",
    "Methods in Natural Language Processing. 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f35fb",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8c598",
   "metadata": {},
   "source": [
    "The following section gives a brief description of all the datasets that are used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40423eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"../../data/hyperbole_detection/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04eb94",
   "metadata": {},
   "source": [
    "### Hyperbole dataset\n",
    "\n",
    "##### The dataset has been taken from the following source:\n",
    "\n",
    "https://github.com/yunx-z/MOVER\n",
    "\n",
    "##### The dataset has been published in this paper: \n",
    "\n",
    "Zhang, Yunxiang, and Xiaojun Wan. \"MOVER: Mask, Over-generate and Rank for Hyperbole Generation.\" arXiv preprint arXiv:2109.07726 (2021).\n",
    "\n",
    "##### Additional information\n",
    "\n",
    "The HYPO-L dataset was translated using Google Sheets. Google Sheets has the ability to use the Google Translate API by invoking a simple function. \n",
    "\n",
    "This is just a temporary solution, the idea is to use a smaller but human translated dataset to train the final model. It will be interesting to compare the results which can be achieved by a model which was trained on machine translated data vs. the performance which is achieved by a model which was trained on human translated data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cf05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERBOLE_DATASET = PATH_TO_DATA + \"hyperbole_machine_translations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e36bd",
   "metadata": {},
   "source": [
    "### Data which is used to compute imageability\n",
    "\n",
    "##### The dataset has been taken from the following source: \n",
    "\n",
    "https://www.ims.uni-stuttgart.de/forschung/ressourcen/experiment-daten/affective-norms/\n",
    "\n",
    "##### The dataset has been published in this paper:\n",
    "\n",
    "Maximilian Köper, Sabine Schulte im Walde\n",
    "Automatically Generated Norms of Abstractness, Arousal, Imageability and Valence for 350,000 German Lemmas\n",
    "In: Proceedings of the 10th Conference on Language Resources and Evaluation (LREC). Portorož, Slovenia, May 2016.\n",
    "\n",
    "##### Additional citings (training resource publications)\n",
    "\n",
    "* Võ et al. (2009)\n",
    "* Lahl et al. (2009)\n",
    "* Kanske and Kotz (2010)\n",
    "* Schmidtke et al. (2014)\n",
    "* The MRC Psycholinguistic Database\n",
    "* Brysbaert et al. (2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa56c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEABILITY_DATASET = PATH_TO_DATA + \"imageability/affective_norms.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1f404",
   "metadata": {},
   "source": [
    "### Data which is used to compute unexpectedness\n",
    "\n",
    "##### The GloVe embeddings have been taken from the following source:\n",
    "\n",
    "https://www.deepset.ai/german-word-embeddings\n",
    "\n",
    "https://int-emb-glove-de-wiki.s3.eu-central-1.amazonaws.com/vectors.txt\n",
    "\n",
    "##### The GloVe embeddings have been published in the following repository:\n",
    "\n",
    "https://gitlab.com/deepset-ai/open-source/glove-embeddings-de\n",
    "\n",
    "##### The Word2Vec embeddings have been taken from the following source:\n",
    "\n",
    "https://www.deepset.ai/german-word-embeddings\n",
    "\n",
    "https://int-emb-word2vec-de-wiki.s3.eu-central-1.amazonaws.com/vectors.txt\n",
    "\n",
    "##### The Word2Vec embeddings have been published in the following repository:\n",
    "\n",
    "https://gitlab.com/deepset-ai/open-source/word2vec-embeddings-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef11b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_VECTORS_DATASET = PATH_TO_DATA + \"glove/glove_vectors.txt\"\n",
    "WORD2VEC_VECTORS_DATASET = PATH_TO_DATA + \"word2vec/word2vec_vectors.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9252536",
   "metadata": {},
   "source": [
    "### Data which is used to compute polarity\n",
    "\n",
    "##### The German version of the SentiWS dataset has been taken from the following source:\n",
    "\n",
    "https://wortschatz.uni-leipzig.de/de/download\n",
    "\n",
    "##### The dataset has been published in the following paper:\n",
    "\n",
    "R. Remus, U. Quasthoff & G. Heyer: SentiWS - a Publicly Available German-language Resource for Sentiment Analysis.\n",
    "In: Proceedings of the 7th International Language Resources and Evaluation (LREC'10), pp. 1168-1171, 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTI_WS_NEGATIVE_DATASET = PATH_TO_DATA + \"polarity/SentiWS_v2.0/SentiWS_v2.0_Negative.txt\"\n",
    "SENTI_WS_POSITIVE_DATASET = PATH_TO_DATA + \"polarity/SentiWS_v2.0/SentiWS_v2.0_Positive.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66992ada",
   "metadata": {},
   "source": [
    "### Main Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6121e4f",
   "metadata": {},
   "source": [
    "The following dataframe will be used as a starting point. All the feature engineering steps will be executed on this dataframe. The current values in the dataframe will not be changed, additional columns will be added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = pd.read_csv(HYPERBOLE_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08415de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ddecd",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101f158",
   "metadata": {},
   "source": [
    "### Imageability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f986ce",
   "metadata": {},
   "source": [
    "Imageability is a feature which is commonly used in metaphor detection. Troiano et al. argumented, that a speaker might try to convey strength while making use of a hyperbole. In such a situation the speaker might use a highly picturable vocabulary. \n",
    "\n",
    "They computed the feature by averaging the imageability values for all words in a sentence.They used a different dataset, as they were working with the English language, the approach is followed as described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_imageability_dict() -> Dict[str, float]:\n",
    "    df = pd.read_csv(IMAGEABILITY_DATASET, sep=\"\\t\")\n",
    "    df[\"WordLower\"] = df[\"Word\"].str.lower()\n",
    "    \n",
    "    return pd.Series(df.IMG.values,index=df.WordLower).to_dict()\n",
    "\n",
    "def get_imageability_of_sentence(sentence: str, dict_imageability: Dict[str, float]) -> float:\n",
    "    words = sentence.lower().split(\" \")\n",
    "    score = 0\n",
    "    \n",
    "    \n",
    "    for word in words:\n",
    "        if word in dict_imageability.keys():\n",
    "            score += dict_imageability[word]\n",
    "    \n",
    "    return score / len(words)\n",
    "\n",
    "def get_imageability(sentences: List[str], dict_imageability: dict) -> List[float]:\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        res.append(get_imageability_of_sentence(sentence,dict_imageability))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def append_imageabilty(df: pd.DataFrame, sentence_column: str, dict_imageability: Dict[str, float]) -> pd.DataFrame:\n",
    "    \n",
    "    sentences = df[sentence_column].tolist()\n",
    "    \n",
    "    values = get_imageability(sentences,dict_imageability)\n",
    "    \n",
    "    df[\"imageability\"] = values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3606d",
   "metadata": {},
   "source": [
    "Generate the dictionary and append the imageability feature to the initial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb657f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_imageability = generate_imageability_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c3bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_imageabilty(df_hyperbole, \"german\",dict_imageability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ba1e3",
   "metadata": {},
   "source": [
    "### Unexpectedness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e65c5e",
   "metadata": {},
   "source": [
    "Unexpectedness is a feature that tries to give a number to the predictability of the words in a sentence. The idea is to have a higher value for a word if the word is used in an unexpected manner. \n",
    "\n",
    "Troiano et al. argued, that word vectors might capture whether a word is used unexpectedly because they encode the contexts in whic terms frequently occurs, as well as contrasts and similarity among their meaning. [1] \n",
    "\n",
    "To compute unexpectedness, Troiano et al. used GloVe embeddings and Word2Vec embeddings. To replicate their approach, german GloVe and Word2Vec embeddings are used. \n",
    "\n",
    "The embeddings are transformed into dictionaries. Afterwards the embedding of each word in a sentence is compared to the embeddings of all the other words in the sentence. (following the approach by Troiano et al.)\n",
    "\n",
    "The average and the minimum value is then taken from the computed values and appended as a new feature column to the initial dataframe. This results in four new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path: str, mode: str) -> Dict[str, np.array]:\n",
    "    \n",
    "    if mode not in [\"glove\",\"word2vec\"]:\n",
    "        print(\"Please specify either glove or word2vec as mode\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Loading \" + mode + \" model\")\n",
    "\n",
    "        word_function = get_word_function(mode)\n",
    "        \n",
    "        model = {}\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            model = get_model_dict(f, word_function)\n",
    "            \n",
    "    print(f\"{len(model)} words loaded!\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_dict(file: TextIO, word_function: Callable[[str], str]) -> Dict[str, np.array]:\n",
    "    \n",
    "    model = {}\n",
    "    \n",
    "    for line in file:\n",
    "        split_line = line.split(\" \")\n",
    "        word = word_function(split_line)\n",
    "        embedding = np.array(split_line[1:],dtype=np.float64)\n",
    "        model[word] = embedding\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_word_function(mode: str) -> Callable[[str], str]:\n",
    "    if mode == \"word2vec\":\n",
    "        return get_word_word2vec_formating\n",
    "    else:\n",
    "        return get_word_glove_formatting\n",
    "\n",
    "def get_word_word2vec_formating(split_line: str) -> str:\n",
    "    return split_line[0].replace(\"'\",\"\")[1:]\n",
    "\n",
    "def get_word_glove_formatting(split_line: str) -> str:\n",
    "    return split_line[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0517f",
   "metadata": {},
   "source": [
    "Methods for calculating unexpectedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unexpectedness_for_sentence(sentence: str, glove_dict: Dict[str, np.array]) -> Tuple[float, float]:\n",
    "    \n",
    "    words = get_filtered_words(sentence,glove_dict)\n",
    "    \n",
    "    results = go_over_all_word_pairs(words,glove_dict)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return (0,0)\n",
    "    \n",
    "    return (mean(results),min(results))\n",
    "    \n",
    "def get_filtered_words(sentence: str, glove_dict: Dict[str, np.array]) -> List[str]:\n",
    "    words = sentence.lower().split(\" \")\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if word in glove_dict.keys():\n",
    "            res.append(word)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def go_over_all_word_pairs(words: List[str] ,glove_dict: Dict[str, np.array]) -> List[float]:\n",
    "\n",
    "    words_compare = words[1:]\n",
    "\n",
    "    res = []\n",
    "    word_comp_index = 1\n",
    "    \n",
    "    for word in words:\n",
    "        for word_comp in words_compare:\n",
    "            res.append(get_cosine_similarity_for_word_pair(word,word_comp,glove_dict))\n",
    "        word_comp_index += 1\n",
    "        words_compare = words[word_comp_index:]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_cosine_similarity_for_word_pair(word1: str, word2: str, glove_dict: Dict[str, np.array]) -> float:\n",
    "    \n",
    "    if word1 in glove_dict.keys() and word2 in glove_dict.keys():\n",
    "    \n",
    "        vector_1 = glove_dict[word1]\n",
    "        vector_2 = glove_dict[word2]\n",
    "        \n",
    "        return get_cosine_simlarity(vector_1,vector_2)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_cosine_simlarity(a: np.array, b: np.array) -> float:\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be58338",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = load_model(GLOVE_VECTORS_DATASET,\"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = load_model(WORD2VEC_VECTORS_DATASET,\"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Das hier ist ein Beispielsatz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unexpectedness_for_sentence(sentence,glove_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unexpectedness_for_sentence(sentence,word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unexpectedness_list(sentences: List[str], dict_model: Dict[str, np.array]) -> List[Tuple[float, float]]:\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        res.append(get_unexpectedness_for_sentence(sentence,dict_model))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_avg_unexpectedness(unexpectedness_list: List[Tuple[float, float]]) -> List[float]:\n",
    "    \n",
    "    return get_values_at_index(unexpectedness_list, 0)\n",
    "\n",
    "def get_min_unexpectedness(unexpectedness_list: List[Tuple[float, float]]) -> List[float]:\n",
    "    \n",
    "    return get_values_at_index(unexpectedness_list, 1)\n",
    "\n",
    "def get_values_at_index(tuple_list: List[Tuple[float,float]], index: int) -> List[float]:  \n",
    "    res = []\n",
    "    \n",
    "    for tup in tuple_list:\n",
    "        res.append(tup[index])\n",
    "    \n",
    "    return res                     \n",
    "\n",
    "def append_unexpectedness(df: pd.DataFrame, sentence_column: str, \n",
    "                          dict_model: Dict[str, np.array], model_name: str) -> pd.DataFrame:\n",
    "    \n",
    "    sentences = df[sentence_column].tolist()\n",
    "    \n",
    "    unexpectedness_list = get_unexpectedness_list(sentences, dict_model)\n",
    "    \n",
    "    values_avg = get_avg_unexpectedness(unexpectedness_list)\n",
    "    values_min = get_min_unexpectedness(unexpectedness_list)\n",
    "    \n",
    "    column_postfix = \"_\" + model_name\n",
    "    column_avg = \"unexpectedness_avg_{}\".format(model_name)\n",
    "    column_min = \"unexpectedness_min_{}\".format(model_name)\n",
    "    \n",
    "    df[column_avg] = values_avg\n",
    "    df[column_min] = values_min\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_unexpectedness(df_hyperbole, \"german\",glove_model,\"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a885b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_unexpectedness(df_hyperbole, \"german\",word2vec_model,\"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a699549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f772fa5",
   "metadata": {},
   "source": [
    "### Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa81b8",
   "metadata": {},
   "source": [
    "Polarity stands for the sentiment of a sentence [1]\n",
    "\n",
    "Troiano et al. used SentiWords and TextBlob for calculating the polarity values. A German version of TextBlob is available and is used below. A German version of the SentiWords dataset is used as well, so that the approach can be followed.\n",
    "\n",
    "Here the polarity is computed for each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95b82d",
   "metadata": {},
   "source": [
    "#### Senti WS Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00371a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = pd.read_csv(SENTI_WS_NEGATIVE_DATASET,sep=\"\\t\")\n",
    "df_neg.columns = [\"Word\",\"Value\",\"WordForms\"]\n",
    "\n",
    "df_pos = pd.read_csv(SENTI_WS_POSITIVE_DATASET,sep=\"\\t\")\n",
    "df_pos.columns = [\"Word\",\"Value\",\"WordForms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e1b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_words_preprocessing(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    df_snip = df[['Value','WordForms']]\n",
    "    df_snip['WordForms'] = df_snip['WordForms'].str.lower().str.split(\",\")\n",
    "    df_all_words = df_snip.explode('WordForms')\n",
    "    df_all_words = df_all_words.reset_index(drop=True)\n",
    "    final_dict = pd.Series(df_all_words.Value.values,index=df_all_words.WordForms).to_dict()\n",
    "    \n",
    "    return final_dict\n",
    "\n",
    "def get_senti_words_polarity_of_sentence(sentence: str, \n",
    "                                         dict_pos: Dict[str, float], dict_neg: Dict[str, float]) -> float:\n",
    "    score = 0\n",
    "    words = sentence.lower().split(\" \")\n",
    "    \n",
    "    for word in words:\n",
    "        if word in dict_pos:\n",
    "            score += dict_pos[word]\n",
    "        elif word in dict_neg:\n",
    "            score += dict_neg[word]\n",
    "    \n",
    "    return score / len(words)\n",
    "\n",
    "def get_senti_words_polarity(sentences: List[str], \n",
    "                             dict_pos: Dict[str, float], dict_neg: Dict[str, float]) -> List[float]:\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        res.append(get_senti_words_polarity_of_sentence(sentence,dict_pos,dict_neg))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def append_senti_ws_polarity(df: pd.DataFrame, sentence_column: str, \n",
    "                             dict_pos: Dict[str, float], dict_neg: Dict[str, float]) -> pd.DataFrame:\n",
    "    \n",
    "    sentences = df[sentence_column].tolist()\n",
    "    \n",
    "    values = get_senti_words_polarity(sentences,dict_pos,dict_neg)\n",
    "    \n",
    "    df[\"polarity_senti_ws\"] = values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dict_pos = senti_words_preprocessing(df_pos)\n",
    "dict_neg = senti_words_preprocessing(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_senti_ws_polarity(df_hyperbole,\"german\",dict_pos,dict_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(TextBlob(\"Hallo Welt\").sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea28ac",
   "metadata": {},
   "source": [
    "#### TextBlob Code (Used for Polarity and Subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_blob_sentiment_of_sentence(sentence: str) -> Tuple[float, float]:\n",
    "    blob = TextBlob(sentence)\n",
    "    return blob.sentiment\n",
    "\n",
    "def get_text_blob_sentiment(sentences: List[str]) -> List[Tuple[float, float]]:\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        res.append(get_text_blob_sentiment_of_sentence(sentence))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_text_blob_polarity(text_blob_sentiment: Tuple[float, float]) -> List[float]:\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for sentiment in text_blob_sentiment:\n",
    "        res.append(sentiment[0])\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_text_blob_subjectivity(text_blob_sentiment: Tuple[float, float]) -> List[float]:\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for sentiment in text_blob_sentiment:\n",
    "        res.append(sentiment[1])\n",
    "    \n",
    "    return res\n",
    "\n",
    "def append_text_blob_polarity(df: pd.DataFrame, text_blob_sentiment: Tuple[float, float]) -> pd.DataFrame:\n",
    "    \n",
    "    values = get_text_blob_polarity(text_blob_sentiment)\n",
    "    \n",
    "    df[\"polarity_text_blob\"] = values\n",
    "    \n",
    "    return df\n",
    "\n",
    "def append_text_blob_subjectivity(df: pd.DataFrame, text_blob_sentiment: Tuple[float, float]) -> pd.DataFrame:\n",
    "    \n",
    "    values = get_text_blob_subjectivity(text_blob_sentiment)\n",
    "    \n",
    "    df[\"subjectivity_text_blob\"] = values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_hyperbole[\"german\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blob_sentiment = get_text_blob_sentiment(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_text_blob_polarity(df_hyperbole,text_blob_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b168da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8938da",
   "metadata": {},
   "source": [
    "### Subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe4f2a",
   "metadata": {},
   "source": [
    "Subjectivity is a feature that describes whether objective information or personal opinion is communicated by a statement [1].\n",
    "\n",
    "The approach is simple to follow, as TextBlob is used again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_text_blob_subjectivity(df_hyperbole,text_blob_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abe317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_subjectivity = pd.DataFrame(df_hyperbole.groupby(['subjectivity_text_blob']).size())\n",
    "table_subjectivity.index = list(table_subjectivity.index)\n",
    "table_subjectivity = table_subjectivity.reset_index()\n",
    "table_subjectivity.columns = [\"subjectivity_value\",\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00773273",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae685670",
   "metadata": {},
   "source": [
    "### Emotional Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc6e36",
   "metadata": {},
   "source": [
    "Emotional intesity describes the strength of sentiment. [1]\n",
    "\n",
    "Troiano et al. used the VADER library to calculate this value. I found a German version of the VADER library (GerVADER).\n",
    "\n",
    "Source: https://github.com/KarstenAMF/GerVADER\n",
    "\n",
    "I take the scores which I can get from GerVADER and append them as new features. The paper unfortunately does not describe which values they were using.\n",
    "\n",
    "##### GerVADER has been published in the following paper: \n",
    "\n",
    "Karsten Michael Tymann, Matthias Lutz, Patrick Palsbröker and Carsten Gips: GerVADER - A German adaptation of the VADER sentiment analysis tool for social media texts. In Proceedings of the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA 2019), Berlin, Germany, September 30 - October 2, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ad39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = gv.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.polarity_scores(\"Hallo Welt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_scores_of_sentence(sentence: str, analyzer: gv.SentimentIntensityAnalyzer) -> Dict[str, float]:\n",
    "    \n",
    "    scores = analyzer.polarity_scores(sentence)\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "def get_vader_scores(sentences: List[str], \n",
    "                     analyzer: gv.SentimentIntensityAnalyzer) -> Tuple[float, float, float, float]:\n",
    "    \n",
    "    res_positive = []\n",
    "    res_neutral = []\n",
    "    res_negative = []\n",
    "    res_compound = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        scores = get_vader_scores_of_sentence(sentence, analyzer)\n",
    "        res_positive.append(scores[\"pos\"])\n",
    "        res_neutral.append(scores[\"neu\"])\n",
    "        res_negative.append(scores[\"neg\"])\n",
    "        res_compound.append(scores[\"compound\"])\n",
    "    \n",
    "    return res_positive, res_neutral, res_negative, res_compound\n",
    "\n",
    "def append_vader_scores(df: pd.DataFrame, sentence_column: str, \n",
    "                        analyzer: gv.SentimentIntensityAnalyzer) -> pd.DataFrame:\n",
    "    \n",
    "    sentences = df[sentence_column].tolist()\n",
    "    \n",
    "    result_tuple = get_vader_scores(sentences, analyzer)\n",
    "    \n",
    "    df[\"vader_positive\"] = result_tuple[0]\n",
    "    df[\"vader_neutral\"] = result_tuple[1]\n",
    "    df[\"vader_negative\"] = result_tuple[2]\n",
    "    df[\"vader_compound\"] = result_tuple[3]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole = append_vader_scores(df_hyperbole, \"german\", analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b030e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column_selection = [\"german\",\"vader_positive\",\"vader_neutral\",\"vader_negative\",\"vader_compound\"]\n",
    "df_hyperbole[column_selection].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4403224",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c8cfa",
   "metadata": {},
   "source": [
    "The initial dataset with all the additional features is exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73723640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyperbole.to_csv(PATH_TO_DATA + \"hyperboles_feature_engineered.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
