{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "import sys\n",
    "sys.path.append(\"wikipedia_wordclouds/\")\n",
    "sys.path.append(\"inverted_index/\")\n",
    "from wikipedia_wordclouds.wikipedia_corpus_creator import WikiCorpusCreator\n",
    "from inverted_index.inverted_index import InvertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_POLITICIANS_PARTY_MAPPING = \"../../data/speaker_party_unique.csv\"\n",
    "PATH_TO_ALL_TAGGED_STATEMENTS = \"../../data/protocol_obtainment/political_statements_thesis.csv\"\n",
    "PATH_TO_DEWAC_CORPUS = \"../../big_datasets/sorted.de.word.unigrams\"\n",
    "\n",
    "TARGET_PATH_FREQUENCY_LIST = \"../../data/research_question_1/preprocessed_frequency_list.csv\"\n",
    "TARGET_PATH_TAGGED_WITH_PARTY = \"../../data/tagged_with_party.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad75f3",
   "metadata": {},
   "source": [
    "First the two datasets are going to be joined together, so that only statements are left where the unique speaker and the speakers party could be added to the dataset containing the speeches. This is important as a lot of speakers are written in multiple slightly different forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a06ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party_mapping = pd.read_csv(PATH_TO_POLITICIANS_PARTY_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb65d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_tagged = pd.read_csv(PATH_TO_ALL_TAGGED_STATEMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_all_tagged.join(df_party_mapping.set_index('speaker'), on='speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0672d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = df_joined[~df_joined[\"party\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.to_csv(TARGET_PATH_TAGGED_WITH_PARTY,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898281a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c34b4c",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128dc36",
   "metadata": {},
   "source": [
    "The following blocks show the preparation of the frequency list and a simple example using the approach which is based on the frequency list. The input is always the article from Wikipedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ca656",
   "metadata": {},
   "source": [
    "Get text from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcc = WikiCorpusCreator(\"Klimawandel\",exclude_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1314538",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = wcc.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95b5a1",
   "metadata": {},
   "source": [
    "Create the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed49809",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_index = InvertedIndex(TARGET_PATH_TAGGED_WITH_PARTY, \"speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14582be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_index.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_documents_containing_words_in_corpus(inverted_index, word_set):\n",
    "    \n",
    "    res = []\n",
    "    results_per_word = dict()\n",
    "    \n",
    "    for word in word_set:\n",
    "        results = invert_index.search(word)\n",
    "        \n",
    "        if results is not None:\n",
    "            res.extend(results)\n",
    "            results_per_word[word] = len(results)\n",
    "        else:\n",
    "            results_per_word[word] = 0\n",
    "    \n",
    "    return set(res), results_per_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1728af",
   "metadata": {},
   "source": [
    "### Individual approach using a large frequency list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68939d9",
   "metadata": {},
   "source": [
    "https://wacky.sslmit.unibo.it/doku.php?id=frequency_lists\n",
    "\n",
    "\n",
    "\n",
    "https://www.sketchengine.eu/dewac-german-corpus/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f55b89",
   "metadata": {},
   "source": [
    "Preprocessing of the dewac corpus:\n",
    "* replaced space with tab in vim using ```:%s/\\s/\\t/g```\n",
    "* removed the entry \" (line 7) as it caused problems while reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcfca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vim -c \"%s/\\s/\\t/g | wq\" ../../big_datasets/sorted.de.word.unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955eb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vim -c \"7d | wq\" ../../big_datasets/sorted.de.word.unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc2d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies = pd.read_csv(PATH_TO_DEWAC_CORPUS,encoding=\"Latin-1\",sep=\"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies.columns = [\"amount\",\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594cb8d",
   "metadata": {},
   "source": [
    "Preprocessing of the unigrams file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375016b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_is_word(input_string):\n",
    "    \n",
    "    if input_string.isupper():\n",
    "        return False\n",
    "    \n",
    "    return bool(re.match(\"^[A-Za-zÖÄÜöäüß]+$\",input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9df7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies[\"word\"] = df_frequencies[\"word\"].apply(lambda inp: str(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies[\"is_word\"] = df_frequencies[\"word\"].apply(lambda inp: string_is_word(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies[\"word_length\"] = df_frequencies[\"word\"].apply(lambda word: len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60eb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies[\"amount_unique_characters\"] = df_frequencies[\"word\"].apply(lambda word: len(''.join(set(word.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies_preprocessed = df_frequencies[\n",
    "    (df_frequencies[\"is_word\"]) & \n",
    "    (df_frequencies[\"word_length\"] > 3) & \n",
    "    (df_frequencies[\"amount_unique_characters\"] > 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc666a3",
   "metadata": {},
   "source": [
    "Filter for words that appear greater than 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_filtered = df_frequencies_preprocessed[(df_frequencies_preprocessed[\"amount\"] > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4cfd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed_filtered[\"percentage\"] = df_preprocessed_filtered[\"amount\"] / df_preprocessed_filtered[\"amount\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_filtered[[\"word\",\"amount\",\"word_length\",\"amount_unique_characters\",\"percentage\"]].to_csv(TARGET_PATH_FREQUENCY_LIST,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5bddb6",
   "metadata": {},
   "source": [
    "Create a dict with percentage and word, this is used for the classification later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_percentage_dict = pd.Series(df_preprocessed_filtered.percentage.values,index=df_preprocessed_filtered.word).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_percentage = float(df_preprocessed_filtered[\"percentage\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ed8e5",
   "metadata": {},
   "source": [
    "Define functions that are used for finding specific words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_words(text, word_dict, treshold, consider_words = None):\n",
    "    tokens = nltk.word_tokenize(text, language='german')\n",
    "    res = []\n",
    "    \n",
    "    # define the output of the function 'f' based on the input parameter\n",
    "    # 'consider_words'\n",
    "    if consider_words is not None:\n",
    "        def f(word):\n",
    "            return classify_word_as_specific_word(word,word_percentage_dict,mean_percentage, consider_words)\n",
    "    else:\n",
    "        def f(word):\n",
    "            return classify_word_as_specific_word(word,word_percentage_dict,mean_percentage)\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word[0].isupper():\n",
    "            if f(word):\n",
    "                res.append(word)\n",
    "                \n",
    "    return set(res)\n",
    "    \n",
    "\n",
    "def classify_word_as_specific_word(word, word_dict, threshold, consider_words = None):\n",
    "    \n",
    "    if consider_words is not None:\n",
    "        for w in consider_words:\n",
    "            if w in word:\n",
    "                return True\n",
    "    \n",
    "    if len(word) < 4:\n",
    "        return False\n",
    "    \n",
    "    if word in word_dict:\n",
    "        if word_dict[word] < threshold:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_documents_per_term_ordered(documents,reverse=True):\n",
    "    \n",
    "    return dict(sorted(documents[1].items(), key=lambda item: item[1],reverse=reverse))\n",
    "\n",
    "\n",
    "def get_indices_from_documents(documents):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for entry in documents[0]:\n",
    "        res.append(entry[0])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1d2ce",
   "metadata": {},
   "source": [
    "The topic-related terms are extracted and stored in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set_climate = get_specific_words(text, \n",
    "                                      word_percentage_dict, \n",
    "                                      mean_percentage, \n",
    "                                      consider_words=[\"Klima\",\"Treibhaus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb05b7b",
   "metadata": {},
   "source": [
    "The documents are retrieved, the indices are stored in a list and the topic-related terms are counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_climate = find_all_documents_containing_words_in_corpus(invert_index, word_set_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a49d73",
   "metadata": {},
   "source": [
    "Shows the amount of documents that were found per topic-related term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_documents_per_term_ordered(documents_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaab67f",
   "metadata": {},
   "source": [
    "All the indices (from the dataframe) are stored in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_climate = get_indices_from_documents(documents_climate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab8703",
   "metadata": {},
   "source": [
    "The speeches are extracted from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ee025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate_speeches = df_preprocessed.iloc[indices_climate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate_speeches.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
